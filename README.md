# DevHire â€“ AI-Powered LinkedIn Job Application Automation

[![Demo Video](https://img.shields.io/badge/ğŸ¬_Demo-Watch_Video-red?style=for-the-badge)](https://www.loom.com/share/ae8227b5df5446669f74b63288176082)

## ğŸ¬ Demo Video

Watch the full product demo to see DevHire in action:

[![DevHire Demo](https://cdn.loom.com/sessions/thumbnails/ae8227b5df5446669f74b63288176082-with-play.gif)](https://www.loom.com/share/ae8227b5df5446669f74b63288176082)

ğŸ‘‰ **[Watch Full Demo on Loom](https://www.loom.com/share/ae8227b5df5446669f74b63288176082)**

---

## ğŸ¯ The Problem It Solves

Applying to jobs on LinkedIn is **tedious, time-consuming, and repetitive**. Professionals spend hours:
- Manually searching for relevant job postings
- Reading job descriptions to find matches
- Customizing resumes for each application
- Filling out LinkedIn forms repeatedly
- Tracking which jobs they've applied to

**DevHire automates this entire workflow**, enabling job seekers to apply to dozens of relevant positions in minutes instead of hours, with AI-powered resume customization tailored to each job.

---

## ğŸš€ What DevHire Does

DevHire is a **full-stack AI automation platform** that:

1. **Extracts Your Profile** â€“ Uses a Chrome extension to capture LinkedIn credentials, cookies, and browser fingerprint
2. **Parses Your Resume** â€“ Analyzes your resume using Google Gemini AI to extract skills, experience, and qualifications
3. **Searches for Jobs** â€“ Scrapes LinkedIn using Playwright (headless browser) based on parsed job titles and keywords from your resume
4. **Tailors Resumes** â€“ Uses Google Gemini to dynamically generate job-specific resumes for each application with LaTeX rendering to PDF (supports **4 professional templates**)
5. **Auto-Applies** â€“ Programmatically fills out LinkedIn's Easy Apply forms and submits applications with tailored resumes
6. **Generates Portfolios** â€“ ğŸ†• **AI-powered portfolio website generator** creates professional HTML/CSS portfolio pages from your resume (supports **5 templates**)
7. **Tracks Progress** â€“ Provides real-time progress tracking and application history in the web dashboard
8. **Persistent Sessions** â€“ ğŸ†• Stores LinkedIn browser context in database for seamless session resumption

**Result:** Apply to 50+ tailored job applications in the time it used to take to apply to 5.

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Frontend (Next.js 15 + React 19)             â”‚
â”‚  âœ¨ Dashboard, Login, Job Selection, Apply Flow    â”‚
â”‚  ğŸ†• Portfolio Builder, Pricing Plans, Password Resetâ”‚
â”‚         Supabase Auth + Prisma ORM                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†• (API calls)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Backend (Python FastAPI + Uvicorn)              â”‚
â”‚  â€¢ /get-jobs â€“ Parse resume & scrape LinkedIn     â”‚
â”‚  â€¢ /apply-jobs â€“ Apply with tailored resumes      â”‚
â”‚  â€¢ /tailor â€“ AI resume customization (Gemini)     â”‚
â”‚  â€¢ /store-cookie â€“ Receive auth from extension    â”‚
â”‚  â€¢ ğŸ†• /portfolio â€“ AI portfolio website generator â”‚
â”‚  â€¢ ğŸ†• /logout â€“ Clear LinkedIn context            â”‚
â”‚  â€¢ ğŸ†• /debug/* â€“ Visual debugging dashboard       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†• (Browser control)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Chrome Extension (Manifest V3)                   â”‚
â”‚  â€¢ Captures LinkedIn cookies & localStorage       â”‚
â”‚  â€¢ Sends credentials to backend                   â”‚
â”‚  â€¢ Injects content scripts for data collection    â”‚
â”‚  â€¢ ğŸ†• Browser fingerprint collection              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agents (Async Python Tasks)                      â”‚
â”‚  â€¢ Scraper Agent â€“ LinkedIn job search (Playwright)â”‚
â”‚  â€¢ Parser Agent â€“ Resume analysis (Gemini AI)      â”‚
â”‚  â€¢ Tailor Agent â€“ Resume generation (Gemini)      â”‚
â”‚  â€¢ Apply Agent â€“ Form filling & submission         â”‚
â”‚  â€¢ ğŸ†• Portfolio Agent â€“ Website generation (Groq) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Databases                                        â”‚
â”‚  â€¢ PostgreSQL (Prisma ORM) â€“ Users, applied jobs  â”‚
â”‚  â€¢ ğŸ†• LinkedIn Context Storage â€“ Session persist  â”‚
â”‚  â€¢ Supabase â€“ Authentication & Auth helpers       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Frontend** | Next.js 15, React 19, TypeScript | User dashboard, job browsing, application tracking, portfolio builder |
| **Backend** | Python FastAPI, Uvicorn | Job scraping, resume tailoring, form automation, portfolio generation |
| **AI Engines** | Google Gemini 2.5 Flash + Groq GPT | Resume parsing, job-resume matching, tailored resume generation, portfolio creation |
| **Browser Automation** | Playwright (async) | LinkedIn login, job scraping, form filling |
| **Auth** | Supabase + JWT + AES-256 | User registration, login, session management, credential encryption |
| **Database** | PostgreSQL + Prisma | User profiles, applied jobs, resume URLs, LinkedIn context |
| **Extension** | Chrome Manifest V3 | Cookie/fingerprint capture, credential sync, session persistence |

---

## ğŸ“ Project Structure

```
DevHire/
â”œâ”€â”€ my-fe/                          # Next.js Frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ Components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx           # Landing page hero section
â”‚   â”‚   â”‚   â”œâ”€â”€ Jobs.tsx           # Job search & listing
â”‚   â”‚   â”‚   â”œâ”€â”€ Apply.tsx          # Application progress tracker
â”‚   â”‚   â”‚   â”œâ”€â”€ Tailor_resume.tsx  # Resume tailoring UI
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.tsx          # Authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ Register.tsx       # ğŸ†• User registration with validation
â”‚   â”‚   â”‚   â”œâ”€â”€ ResetPass.tsx      # ğŸ†• Password reset flow
â”‚   â”‚   â”‚   â”œâ”€â”€ JobCards.tsx       # Job card display
â”‚   â”‚   â”‚   â”œâ”€â”€ PortfolioPage.tsx  # ğŸ†• AI portfolio builder UI
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.tsx         # Navigation with session management
â”‚   â”‚   â”‚   â”œâ”€â”€ Features.tsx       # Feature showcase with animations
â”‚   â”‚   â”‚   â”œâ”€â”€ Linkedin.tsx       # LinkedIn credentials input
â”‚   â”‚   â”‚   â”œâ”€â”€ About.jsx          # About page
â”‚   â”‚   â”‚   â”œâ”€â”€ Pricing/           # ğŸ†• Pricing plans (Basic/Pro)
â”‚   â”‚   â”‚   â””â”€â”€ Landing-Page/      # Landing page components
â”‚   â”‚   â”œâ”€â”€ api/                   # Backend API routes (Next.js)
â”‚   â”‚   â”‚   â”œâ”€â”€ store/             # ğŸ†• Encrypted credential storage
â”‚   â”‚   â”‚   â”œâ”€â”€ get-data/          # ğŸ†• Retrieve encrypted credentials
â”‚   â”‚   â”‚   â””â”€â”€ User/              # User CRUD operations
â”‚   â”‚   â”œâ”€â”€ Jobs/                  # Job pages
â”‚   â”‚   â”‚   â”œâ”€â”€ LinkedinUserDetails/ # LinkedIn login page
â”‚   â”‚   â”‚   â”œâ”€â”€ tailor/            # Resume tailoring page
â”‚   â”‚   â”‚   â””â”€â”€ portfolio/         # ğŸ†• Portfolio builder page
â”‚   â”‚   â”œâ”€â”€ apply/                 # Application flow pages
â”‚   â”‚   â”œâ”€â”€ login/                 # Login page
â”‚   â”‚   â”œâ”€â”€ register/              # ğŸ†• Registration page
â”‚   â”‚   â”œâ”€â”€ reset-password/        # ğŸ†• Password reset page
â”‚   â”‚   â”œâ”€â”€ pricing/               # ğŸ†• Pricing page
â”‚   â”‚   â”œâ”€â”€ about/                 # About page
â”‚   â”‚   â””â”€â”€ utiles/
â”‚   â”‚       â”œâ”€â”€ agentsCall.ts      # API calls to Python backend
â”‚   â”‚       â”œâ”€â”€ supabaseClient.ts  # Supabase initialization
â”‚   â”‚       â”œâ”€â”€ getUserData.ts     # User profile management
â”‚   â”‚       â”œâ”€â”€ useUploadResume.ts # ğŸ†• Resume upload hook
â”‚   â”‚       â”œâ”€â”€ database.ts        # ğŸ†• Prisma client
â”‚   â”‚       â””â”€â”€ api.ts             # ğŸ†• API URL configuration
â”‚   â”œâ”€â”€ prisma/
â”‚   â”‚   â””â”€â”€ schema.prisma          # Database schema (PostgreSQL)
â”‚   â”œâ”€â”€ context/                   # React context providers
â”‚   â”œâ”€â”€ store/                     # Redux store configuration
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend_python/                # Python FastAPI Backend
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ main.py               # FastAPI app setup
â”‚   â”‚   â”œâ”€â”€ progress_dict.py      # ğŸ†• Shared progress tracking
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ list_jobs.py      # GET /get-jobs endpoint
â”‚   â”‚       â”œâ”€â”€ apply_jobs.py     # POST /apply-jobs endpoint
â”‚   â”‚       â”œâ”€â”€ get_resume.py     # POST /tailor endpoint
â”‚   â”‚       â”œâ”€â”€ cookie_receiver.py # POST /store-cookie endpoint
â”‚   â”‚       â”œâ”€â”€ progress_route.py # Progress tracking
â”‚   â”‚       â”œâ”€â”€ portfolio_generator.py # ğŸ†• Portfolio generation endpoint
â”‚   â”‚       â”œâ”€â”€ logout.py         # ğŸ†• LinkedIn context cleanup
â”‚   â”‚       â”œâ”€â”€ debug_routes.py   # ğŸ†• Visual debugging dashboard
â”‚   â”‚       â””â”€â”€ templates/        # ğŸ†• Resume template images
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ scraper_agent.py             # LinkedIn job scraper
â”‚   â”‚   â”œâ”€â”€ scraper_agent_optimized.py   # Optimized async scraper
â”‚   â”‚   â”œâ”€â”€ apply_agent.py               # Form filling & submission
â”‚   â”‚   â”œâ”€â”€ tailor.py                    # Resume AI customization (4 templates)
â”‚   â”‚   â”œâ”€â”€ parse_agent.py               # Resume parsing
â”‚   â”‚   â””â”€â”€ portfolio_agent.py           # ğŸ†• AI portfolio generator (5 templates)
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ db_engine.py          # SQLAlchemy connection
â”‚   â”‚   â”œâ”€â”€ SchemaModel.py        # User model (SQLAlchemy)
â”‚   â”‚   â””â”€â”€ linkedin_context.py   # ğŸ†• LinkedIn session persistence
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ session_manager.py    # ğŸ†• Session management utilities
â”‚   â”œâ”€â”€ data_dump/                # ğŸ†• Playwright persistent storage
â”‚   â”œâ”€â”€ config.py                 # API keys & environment variables
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                # ğŸ†• Docker containerization
â”‚   â”œâ”€â”€ run.sh                    # Linux startup script
â”‚   â””â”€â”€ run.bat                   # ğŸ†• Windows startup script
â”‚
â”œâ”€â”€ extension/                     # Chrome Extension
â”‚   â”œâ”€â”€ manifest.json             # Extension configuration
â”‚   â”œâ”€â”€ background.js             # Service worker (cookie/storage sync)
â”‚   â””â”€â”€ content.js                # Content script (fingerprint collection)
â”‚
â”œâ”€â”€ next-app/                      # ğŸ†• Alternative Next.js app
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ signin/
â”‚   â”‚   â”œâ”€â”€ signup/
â”‚   â”‚   â””â”€â”€ UserDetails/
â”‚   â””â”€â”€ prisma/
â”‚
â”œâ”€â”€ schema.sql                     # ğŸ†• Database SQL schema
â””â”€â”€ prisma/                        # Prisma schema (shared)
    â””â”€â”€ schema.prisma             # Database models
```

---

## ğŸ”„ User Journey & Data Flow

### Step 1: User Authenticates
```
1. User logs in with LinkedIn on DevHire web app
2. Chrome extension captures LinkedIn cookies & localStorage
3. Extension sends data to backend (/store-cookie)
4. Backend stores encrypted credentials for session
```

### Step 2: Resume Upload & Parsing
```
1. User uploads resume (PDF/DOCX)
2. Backend extracts text using PyMuPDF + OCR (pytesseract)
3. Gemini AI parses resume â†’ extracts job titles, skills, experience
4. Output: ["Full Stack Developer, Backend Engineer"] + ["Python, React, PostgreSQL"]
```

### Step 3: Job Search
```
1. Frontend calls POST /get-jobs with:
   - user_id, password, resume_url
2. Backend uses Playwright to:
   - Login to LinkedIn with credentials
   - Search for each parsed job title
   - Scrape job listings (title, company, description, link)
3. Jobs returned to frontend, user selects 10-50 jobs
```

### Step 4: Resume Tailoring (Per Job)
```
1. For each selected job:
   - Frontend calls POST /tailor with:
     - original_resume_url, job_description
2. Backend:
   - Downloads original resume PDF
   - Sends to Gemini: "Tailor this resume for this JD"
   - Gemini generates LaTeX with highlighted relevant skills
   - LaTeX rendered to PDF
   - PDF converted to Base64
3. Base64 PDFs sent to frontend, stored in sessionStorage
```

### Step 5: Batch Application
```
1. Frontend calls POST /apply-jobs with:
   - jobs: [{job_url, job_description}]
   - user_id, password, resume_url
2. Backend applies in parallel batches (15 jobs per batch):
   - Open LinkedIn Easy Apply modal via Playwright
   - Detect form fields (experience, skills, resume upload)
   - Fill fields with tailored answers + upload tailored PDF
   - Click Submit
3. Real-time progress updates via /progress endpoint
4. Applications tracked in PostgreSQL (User.applied_jobs)
```

---

## ğŸ› ï¸ Tech Stack Deep Dive

### Frontend (Next.js)
- **Framework:** Next.js 15.4.6 with App Router
- **Language:** TypeScript + React 19
- **Styling:** Tailwind CSS 4
- **State Management:** Redux Toolkit
- **HTTP:** Axios for API calls
- **Auth:** Supabase Auth + JWT
- **Database ORM:** Prisma Client
- **Animations:** Framer Motion
- **UI Feedback:** React Hot Toast (notifications)
- **PDF Handling:** PDF.js for rendering

### Backend (Python)
- **Framework:** FastAPI (async web server)
- **Async Runtime:** Uvicorn (ASGI)
- **Browser Automation:** Playwright (async headless browser)
- **Database:** PostgreSQL + SQLAlchemy ORM
- **AI Models:**
  - Google Gemini 2.5 Flash (resume parsing, tailoring) with fallback chain
  - Groq GPT-oss-120b (portfolio generation)
- **PDF Processing:** PyMuPDF (fitz), pdf2image, pytesseract (OCR)
- **Resume Generation:** LaTeX rendering (4 templates), FPDF, python-docx
- **Portfolio Generation:** HTML/CSS (5 templates)
- **HTTP:** aiohttp for async requests
- **Auth:** browser-cookie3 for session cookies
- **Containerization:** Docker support

### Database (PostgreSQL + Prisma)
```prisma
model User {
  id                 String    @id @default(uuid()) @db.Uuid
  email              String    @unique
  name               String?
  resume_url         String?
  applied_jobs       String[]  // Array of LinkedIn job URLs applied to
  linkedin_context   Json?     // ğŸ†• Playwright browser session state
  context_updated_at DateTime? // ğŸ†• LinkedIn context last update timestamp
}
```

### Chrome Extension
- **Manifest:** V3 (latest standard)
- **Service Worker:** background.js (cookie sync every 2 minutes)
- **Content Script:** content.js (data injection + fingerprint collection)
- **Capabilities:** 
  - Cookie capture (`.linkedin.com` and `www.linkedin.com` domains)
  - localStorage/sessionStorage access
  - ğŸ†• Browser fingerprint collection (userAgent, platform, language, timezone, hardware info, screen dimensions, viewport size, pixel ratio, color depth)
  - ğŸ†• SPA navigation detection for re-injection

---

## ğŸš€ Getting Started

### Prerequisites
- **Node.js** â‰¥ 20
- **Python** 3.9+
- **PostgreSQL** database (local or cloud)
- **Google API Key** (Gemini access)
- **Supabase Project** (optional, for auth)
- **Chrome Browser** (for extension & Playwright)

### Environment Setup

#### 1. Clone & Install Frontend
```bash
cd my-fe
npm install
npx prisma generate  # Generate Prisma Client
```

Create `.env.local`:
```
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_key
NEXT_PUBLIC_API_URL=http://localhost:8000
DATABASE_URL=postgresql://user:password@localhost:5432/devhire
```

#### 2. Install Backend Dependencies
```bash
cd backend_python
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
playwright install  # Download browser binaries
```

Create `config.py`:
```python
GOOGLE_API = "your_gemini_api_key"
GROQ_API = "your_groq_api_key"  # For portfolio generation
LINKEDIN_ID = "your_linkedin_email"
LINKEDIN_PASSWORD = "your_linkedin_password"
```

#### 3. Setup Database
```bash
cd my-fe
npx prisma migrate dev --name init
```

#### 4. Run Backend
```bash
cd backend_python
python -m uvicorn main.main:app --reload --host 0.0.0.0 --port 8000
```

#### 5. Run Frontend
```bash
cd my-fe
npm run dev
```

Open `http://localhost:3000` in browser.

#### 6. Load Chrome Extension
1. Open `chrome://extensions/`
2. Enable "Developer mode"
3. Click "Load unpacked"
4. Select `DevHire/extension/` folder

---

## ğŸ”‘ Key Features & Examples

### Feature 1: Smart Job Parsing
**Input:** Resume PDF
**Process:** 
- Extract text with OCR
- Send to Gemini: "Extract job titles and technical skills"
- Parse response
**Output:** `["Full Stack Developer", "Backend Engineer"] + ["Python", "React", "PostgreSQL", ...]`

### Feature 2: Intelligent Resume Tailoring (4 Templates)
**Input:** Original resume + Job description
**Templates Available:**
- Classic Professional
- Modern Minimalist
- Technical Focus
- Creative Design

**Process:**
```python
prompt = f"""
Given this resume:
{resume_text}

And this job description:
{job_description}

Generate a tailored resume in LaTeX that:
1. Highlights relevant skills
2. Reorders experience by relevance
3. Emphasizes matching technologies
"""
response = gemini_model.generate_content(prompt)
# Response is LaTeX â†’ rendered to PDF â†’ Base64
```
**Output:** Customized PDF resume (Base64 encoded)

### Feature 3: ğŸ†• AI Portfolio Website Generator (5 Templates)
**Input:** Resume data + Selected template
**Templates Available:**
1. Modern Developer Portfolio
2. Minimalist Professional
3. Creative Designer
4. Tech Startup Style
5. Corporate Executive

**Process:**
```python
# Uses Groq GPT-oss-120b for HTML/CSS generation
prompt = f"""
Generate a complete, responsive portfolio website HTML/CSS based on:
- Resume data: {resume_data}
- Template style: {template_id}

Include sections for: About, Skills, Experience, Projects, Contact
"""
response = groq_client.generate(prompt)
# Returns production-ready HTML/CSS
```
**Output:** Complete HTML/CSS portfolio page with live preview

### Feature 4: Automated Job Application
**Example Flow:**
```python
# 1. Playwright opens LinkedIn Easy Apply
await page.click('button:has-text("Easy Apply")')

# 2. Detect form fields
experience_field = await page.query_selector('input[name="experience"]')
skills_field = await page.query_selector('input[name="skills"]')

# 3. Fill with AI-suggested answers
await experience_field.fill("5 years in Full Stack Development")
await skills_field.fill("Python, React, PostgreSQL")

# 4. Upload tailored resume
resume_input = await page.query_selector('input[type="file"]')
await resume_input.set_input_files(tailored_resume_path)

# 5. Submit
await page.click('button:has-text("Submit application")')
```

### Feature 5: ğŸ†• LinkedIn Session Persistence
**Process:**
```python
# Save browser context to database
await save_linkedin_context(
    email=user_email,
    context={
        "storage_state": browser_context.storage_state(),
        "cookies": cookies,
        "localStorage": local_storage
    }
)

# Restore session on next visit - no re-login needed!
context = await load_linkedin_context(user_email)
browser_context = await browser.new_context(storage_state=context)
```

### Feature 6: ğŸ†• Visual Debugging Dashboard
**Endpoints:**
- `/debug/screenshots` - View all debug screenshots
- `/debug/gallery` - HTML gallery for visual inspection
- `/debug/images` - Get images from recent scraper runs

---

## ï¿½ Pricing Plans

| Feature | Basic (Free) | Pro (â‚¹199/month) |
|---------|--------------|------------------|
| Job Applications | 10/month | Unlimited |
| Resume Tailoring | 5/month | Unlimited |
| Portfolio Generation | 1 template | All 5 templates |
| LinkedIn Context Persistence | âŒ | âœ… |
| Priority Support | âŒ | âœ… |

---

## ï¿½ğŸ“Š Performance & Metrics

| Metric | Value |
|--------|-------|
| **Jobs Applied Per Hour** | 50-100 (vs. 5-10 manual) |
| **Resume Customization Time** | <5 seconds per job (Gemini) |
| **Job Scraping Speed** | 20-30 jobs/minute |
| **End-to-End Application Time** | 10-15 minutes for 50 jobs |
| **Success Rate (Easy Apply)** | ~85% (varies by form complexity) |

---

## ğŸ”’ Security & Privacy

### Credential Handling
- LinkedIn credentials encrypted with AES-256-CBC
- Session-based authentication (JWT)
- Credentials stored in HTTP-only cookies (encrypted)
- LinkedIn context stored in PostgreSQL (session persistence)

### Data Protection
- CORS middleware restricts to authorized origins (extension ID + Vercel production URL)
- Supabase Auth for user verification
- PostgreSQL for encrypted data at rest

### LinkedIn Compliance
- Uses official LinkedIn API where available
- Respects robots.txt and rate limits
- Stealth mode Playwright (mimics human behavior)

---

## ğŸ› Troubleshooting

### "Cannot use import statement outside a module"
**Solution:** Ensure `package.json` has `"type": "module"`

### "Playwright browser download failed"
**Solution:** Run `playwright install` after pip install

### "Gemini API rate limit exceeded"
**Solution:** Add delays between tailoring requests (5-10 second intervals). The system has automatic fallback to: `gemini-2.5-flash` â†’ `gemini-2.5-flash-lite` â†’ `gemini-2.0-flash` â†’ `gemini-1.5-flash`

### "LinkedIn login failing"
**Solution:**
- Update `LINKEDIN_ID` and `LINKEDIN_PASSWORD` in `config.py`
- Check if LinkedIn has changed login flow (inspect with DevTools)
- Ensure 2FA is disabled or use app passwords
- Use the debug dashboard at `/debug/gallery` to see screenshots

### "Resume tailoring returns LaTeX errors"
**Solution:** Retry with simpler job description or increase context length in Gemini prompt

### "Portfolio generation not working"
**Solution:** 
- Ensure Groq API key is configured in `config.py`
- Check that resume data is properly parsed
- Try a different template

### "LinkedIn context not persisting"
**Solution:**
- Check database connection in `db_engine.py`
- Verify `linkedin_context` column exists in User table
- Run database migrations: `npx prisma migrate dev`

---

## ğŸ“š API Endpoints

### Frontend Calls Backend

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/get-jobs` | POST | Parse resume & fetch matching jobs from LinkedIn |
| `/apply-jobs` | POST | Apply to selected jobs with tailored resumes |
| `/tailor` | POST | Generate AI-tailored resume for a job |
| `/store-cookie` | POST | Receive LinkedIn cookies from extension |
| `/progress` | GET | Real-time application progress tracking |
| `/portfolio` | POST | ğŸ†• Generate AI-powered portfolio website |
| `/portfolio/templates` | GET | ğŸ†• Get available portfolio templates |
| `/templates` | GET | ğŸ†• Get available resume templates |
| `/logout` | DELETE | ğŸ†• Clear LinkedIn context from database |
| `/progress/scraping/{email}` | GET | ğŸ†• Job scraping progress by user |
| `/progress/applying/{email}` | GET | ğŸ†• Application progress by user |

### Debug Endpoints (Development)

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/debug/capture` | GET | ğŸ†• Capture screenshot with Playwright |
| `/debug/screenshot` | GET | ğŸ†• Get captured screenshot |
| `/debug/html` | GET | ğŸ†• Get captured HTML |
| `/debug/screenshots` | GET | ğŸ†• Get all debug screenshots as base64 |
| `/debug/images` | GET | ğŸ†• Get debug images from scraper runs |
| `/debug/gallery` | GET | ğŸ†• HTML gallery to view screenshots |
| `/debug/cleanup` | DELETE | ğŸ†• Clear old debug files |

### Next.js API Routes

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/store` | POST | ğŸ†• Encrypt LinkedIn credentials (AES-256-CBC) |
| `/api/get-data` | GET | ğŸ†• Retrieve encrypted credentials |
| `/api/User?action=insert` | POST | ğŸ†• Create new user |
| `/api/User?action=update` | POST | ğŸ†• Update user data |
| `/api/User?id={id}` | GET | ğŸ†• Fetch user by ID |

### Example Requests

```bash
# Parse resume & get jobs
curl -X POST http://localhost:8000/get-jobs \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user123",
    "file_url": "https://..../resume.pdf",
    "password": "linkedin_password"
  }'

# Tailor resume for a job
curl -X POST http://localhost:8000/tailor \
  -H "Content-Type: application/json" \
  -d '{
    "job_desc": "We are looking for a Full Stack Developer...",
    "resume_url": "https://..../resume.pdf"
  }'

# Apply to jobs
curl -X POST http://localhost:8000/apply-jobs \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "user123",
    "password": "linkedin_password",
    "resume_url": "https://..../resume.pdf",
    "jobs": [
      {
        "job_url": "https://linkedin.com/jobs/123456",
        "job_description": "Full Stack Developer..."
      }
    ]
  }'

# ğŸ†• Generate portfolio website
curl -X POST http://localhost:8000/portfolio \
  -H "Content-Type: application/json" \
  -d '{
    "resume_url": "https://..../resume.pdf",
    "template_id": "modern-developer"
  }'

# ğŸ†• Get available portfolio templates
curl -X GET http://localhost:8000/portfolio/templates

# ğŸ†• Get available resume templates
curl -X GET http://localhost:8000/templates

# ğŸ†• Clear LinkedIn context (logout)
curl -X DELETE http://localhost:8000/logout?email=user@example.com

# ğŸ†• Check scraping progress
curl -X GET http://localhost:8000/progress/scraping/user@example.com

# ğŸ†• Check application progress
curl -X GET http://localhost:8000/progress/applying/user@example.com
```

---

## ğŸ“ Learning Resources

### Understanding Key Workflows

1. **Async Python in Backend**
   - Read: `backend_python/agents/scraper_agent_optimized.py` (async Playwright usage)
   - Learn: How Playwright async contexts handle multiple browser sessions

2. **Resume Tailoring Logic**
   - Read: `backend_python/agents/tailor.py` (Gemini integration)
   - Learn: PDF text extraction, LaTeX generation, batch processing, 4 template system

3. **ğŸ†• Portfolio Generation**
   - Read: `backend_python/agents/portfolio_agent.py` (Groq integration)
   - Learn: HTML/CSS generation from resume data, 5 template system

4. **Frontend State Management**
   - Read: `my-fe/app/Components/Jobs.tsx` & `Apply.tsx`
   - Learn: Redux + sessionStorage for multi-step flows

5. **ğŸ†• Portfolio Builder UI**
   - Read: `my-fe/app/Components/PortfolioPage.tsx`
   - Learn: Template selection, live preview, code export

6. **Database Models**
   - Read: `my-fe/prisma/schema.prisma` & `backend_python/database/SchemaModel.py`
   - Learn: How Prisma ORM mirrors SQLAlchemy models, LinkedIn context storage

7. **ğŸ†• LinkedIn Session Persistence**
   - Read: `backend_python/database/linkedin_context.py`
   - Learn: Browser context serialization and restoration

---

## ğŸ¤ Contributing

1. Create a feature branch: `git checkout -b feature/your-feature`
2. Make changes and test locally
3. Commit with clear messages: `git commit -m "Add resume parsing optimization"`
4. Push and create a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License â€“ see LICENSE file for details.

---

## ğŸ‰ Future Enhancements

- [ ] Support for multiple job boards (Indeed, Glassdoor, Dice)
- [ ] Resume versioning & A/B testing
- [ ] Salary negotiation insights
- [ ] Interview prep with AI coaching
- [ ] Email notification tracking
- [ ] Mobile app (React Native)
- [ ] API marketplace for third-party integrations
- [ ] Cover letter generation
- [ ] Application analytics dashboard
- [ ] Multi-language resume support

---

## ğŸ“§ Contact & Support

**For issues, questions, or feature requests:**
- Open an issue on GitHub
- Email: support@devhire.dev
- Discord: [Join our community](https://discord.gg/devhire)

---

**Made with â¤ï¸ to help developers land their dream jobs faster.**

---

## ğŸ“‹ Changelog

### Latest Updates (v2.0)
- âœ… **AI Portfolio Generator** - Create professional portfolio websites from your resume
- âœ… **5 Portfolio Templates** - Modern, Minimalist, Creative, Startup, Corporate styles
- âœ… **4 Resume Templates** - Choose from multiple LaTeX resume designs
- âœ… **LinkedIn Session Persistence** - No more re-logging in every session
- âœ… **Visual Debugging Dashboard** - See exactly what the scraper sees
- âœ… **Pricing System** - Basic (Free) and Pro tiers
- âœ… **Password Reset Flow** - Full Supabase-powered password recovery
- âœ… **Browser Fingerprint Collection** - Enhanced session authenticity
- âœ… **Docker Support** - Easy containerized deployment
- âœ… **Windows Support** - `run.bat` for Windows users
- âœ… **Groq AI Integration** - Additional AI model for portfolio generation
- âœ… **Gemini Fallback Chain** - Automatic failover between Gemini models
